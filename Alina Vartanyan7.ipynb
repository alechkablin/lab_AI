{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89184a75-273c-43e5-80f4-52123ef42347",
   "metadata": {},
   "source": [
    "# Нейронные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef66781-fe10-4deb-a6ab-5141379757e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, -0.1]\n",
      "-1\n",
      "1\n",
      "1\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "#пример 1.1.1\n",
    "#класс, который реализует персептрон и его обучение\n",
    "class Perceptron:\n",
    "    def __init__ (self, N):\n",
    "        #создать нулевые веса\n",
    "        self.w = list()\n",
    "        for i in range(N):\n",
    "            self.w.append(0)\n",
    "    #метод для вычисления значения персептрона\n",
    "    def calc(self, x):\n",
    "        res = 0\n",
    "        for i in range(len(self.w)):\n",
    "            res = res + self.w[i] * x[i]\n",
    "        return res \n",
    "    #пороговая функция активации персептрона \n",
    "    def sign(self, x):\n",
    "        if self.calc(x) > 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "    #обучение на одном примере\n",
    "    def learn(self, la, x, y):\n",
    "        #обучаем только когда результат неверный\n",
    "        if y * self.calc(x) <= 0:\n",
    "            for i in range(len(self.w)):\n",
    "                self.w[i] = self.w[i] + la * y * x[i]\n",
    "    #обучение по всем данным Т - кортеж пример \n",
    "    def learning(self, la, T):\n",
    "        # цикл обучения \n",
    "        for n in range(100):\n",
    "            # обучение по всем набору примеров \n",
    "            for t in T:\n",
    "                self.learn(la, t[0], t[1])\n",
    "#создаем класс двумерного персептрона \n",
    "perceptron = Perceptron(2)\n",
    "la = 0.1 #константа обучения\n",
    "#создаем примеры\n",
    "T = list()\n",
    "T.append([[2,1],1])\n",
    "T.append([[3,2],1])\n",
    "T.append([[4,1],1])\n",
    "T.append([[1,2],-1])\n",
    "T.append([[2,3],-1])\n",
    "T.append([[5,7],-1])\n",
    "perceptron.learning(la, T) #обучение персептрона\n",
    "print(perceptron.w) #печатаем веса\n",
    "#проверим работу на тестовых примерах\n",
    "print(perceptron.sign([1.5,2]))\n",
    "print(perceptron.sign([3,1.5]))\n",
    "print(perceptron.sign([5,1]))\n",
    "print(perceptron.sign([5,10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ef4b2-e00f-4a52-9422-d63beff29b3e",
   "metadata": {},
   "source": [
    "# Реализация нейронной сети на Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7434539-f2fc-4a77-8adb-95db7794515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9990889488055994\n"
     ]
    }
   ],
   "source": [
    "# пример 1.1.2\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    # функция активации: f(x) = 1 / (1 + e^(-x))\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward(self,inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "weights = np.array([0,1])\n",
    "bias = 4\n",
    "n = Neuron(weights, bias)\n",
    "x = np.array([2,3])\n",
    "print(n.feedforward(x))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ae29648-0cc0-4704-9499-2139769e3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7216325609518421\n"
     ]
    }
   ],
   "source": [
    "#пример 1.1.3\n",
    "import numpy as np\n",
    "class OurNeuralNetwork:\n",
    "    '''\n",
    "    Данные нейросети:\n",
    "    - два входа\n",
    "    - два нейрона в скрытых слоях (h1,h2)\n",
    "    - выход (о1)\n",
    "    Нейроны имеют идентичные веса и пороги:\n",
    "    - w = [0,1]\n",
    "    - b = 0\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        weights = np.array([0,1])\n",
    "        bias = 0\n",
    "        #Класс Neuron из предыдущего раздела\n",
    "        self.h1 = Neuron(weights, bias)\n",
    "        self.h2 = Neuron(weights, bias)\n",
    "        self.o1 = Neuron(weights, bias)\n",
    "    def feedforward(self,x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        # входы для o1 - это выходы h1 и h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1,out_h2]))\n",
    "        return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2,3])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58eb6f3-3084-4e1e-913e-c7a4ccdd98f1",
   "metadata": {},
   "source": [
    "# Обучение нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e199af8-93b4-4556-bfc1-d7d96226cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n"
     ]
    }
   ],
   "source": [
    "#задание 1\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5]) # w = [1,0]\n",
    "        bias = 0 # b = 1\n",
    "        # Knacc Neuron u3 предыдущего раздела\n",
    "        self.h1 = Neuron(weights, bias) # 1 нейрон\n",
    "        self.h2 = Neuron(weights, bias) # 2 нейрон\n",
    "        self.h3 = Neuron(weights, bias) # 3 нейрон\n",
    "        self.o1 = Neuron(weights, bias) # 1 выход\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        # Входы для o1 — это входы h1 и h2\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array([2, 3, 4])\n",
    "print(network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb295516-c554-4791-a61f-7cc3273ef6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8151036049051821\n",
      "(0.8757270529783324, 0.8757270529783324)\n"
     ]
    }
   ],
   "source": [
    "#задание 2\n",
    "#Sigmoid\n",
    "import numpy as np\n",
    "def sigmoid(x):\n",
    "    sig = 1 / (1 + np.exp(-x))\n",
    "    return sig\n",
    "\n",
    "class Neuron1:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward (self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return sigmoid(total)\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0\n",
    "        self.h1 = Neuron1(weights, bias)\n",
    "        self.h2 = Neuron1(weights, bias)\n",
    "        self.h3 = Neuron1(weights, bias)\n",
    "        self.o1 = Neuron1(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "\n",
    "class OrNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1,0])\n",
    "        bias = 1\n",
    "\n",
    "        self.h1 = Neuron1(weights, bias)\n",
    "        self.h2 = Neuron1(weights, bias)\n",
    "        self.o1 = Neuron1(weights, bias)\n",
    "        self.o2 = Neuron1(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "\n",
    "\n",
    "network = OurNeuralNetwork()\n",
    "x = np.array ([2, 3, 4])\n",
    "print (network.feedforward(x))\n",
    "\n",
    "network = OrNeuralNetwork()\n",
    "x = np.array ([2, 3])\n",
    "print (network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1306db2-f53f-472a-8188-790f0d8b1b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7968426715486405\n",
      "(1.1555911185916798, 1.1555911185916798)\n"
     ]
    }
   ],
   "source": [
    "#Tanh\n",
    "def tanh(x):\n",
    "    return np.tan(x)\n",
    "\n",
    "\n",
    "class Neuron2:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward (self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return tanh(total)\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0 \n",
    "        self.h1 = Neuron2(weights, bias)\n",
    "        self.h2 = Neuron2(weights, bias)\n",
    "        self.h3 = Neuron2(weights, bias)\n",
    "        self.o1 = Neuron2(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array ([2, 3, 4])\n",
    "print (network.feedforward(x))\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1,0])\n",
    "        bias = 1\n",
    "        \n",
    "        self.h1 = Neuron2(weights, bias)\n",
    "        self.h2 = Neuron2(weights, bias)\n",
    "        self.o1 = Neuron2(weights, bias)\n",
    "        self.o2 = Neuron2(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array ([2, 3])\n",
    "print (network.feedforward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f191808e-e054-4c7c-879f-4b55ffb01b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.75\n",
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "#ReLU\n",
    "def ReLU(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "class Neuron3:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "    def feedforward (self, inputs):\n",
    "        total = np.dot(self.weights, inputs) + self.bias\n",
    "        return ReLU(total)\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([0.5, 0.5, 0.5])\n",
    "        bias = 0 \n",
    "        self.h1 = Neuron3(weights, bias)\n",
    "        self.h2 = Neuron3(weights, bias)\n",
    "        self.h3 = Neuron3(weights, bias)\n",
    "        self.o1 = Neuron3(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_h3 = self.h3.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2, out_h3]))\n",
    "        return out_o1\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array ([2, 3, 4])\n",
    "print (network.feedforward(x))\n",
    "\n",
    "class OurNeuralNetwork:\n",
    "    def __init__(self):\n",
    "        weights = np.array([1,0])\n",
    "        bias = 1\n",
    "        \n",
    "        self.h1 = Neuron3(weights, bias)\n",
    "        self.h2 = Neuron3(weights, bias)\n",
    "        self.o1 = Neuron3(weights, bias)\n",
    "        self.o2 = Neuron3(weights, bias)\n",
    "    def feedforward(self, x):\n",
    "        out_h1 = self.h1.feedforward(x)\n",
    "        out_h2 = self.h2.feedforward(x)\n",
    "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n",
    "        out_o2 = self.o2.feedforward(np.array([out_h1, out_h2]))\n",
    "        return out_o1, out_o2\n",
    "    \n",
    "network = OurNeuralNetwork()\n",
    "x = np.array ([2, 3])\n",
    "print (network.feedforward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f581dd-7b56-4506-8ad3-67ab944e0ab6",
   "metadata": {},
   "source": [
    "# Введение в нейронные сети с помощью Scikit-Learn в Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14895020-18cc-4f0a-86c0-546a644b8e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:  (150, 4) (150,)\n",
      "(120, 4) (30, 4) (120,) (30,)\n",
      "['Versicolor' 'Setosa' 'Virginica' 'Virginica' 'Setosa' 'Setosa'\n",
      " 'Virginica' 'Virginica' 'Virginica' 'Setosa' 'Setosa' 'Versicolor'\n",
      " 'Virginica' 'Versicolor' 'Virginica']\n",
      "80     Versicolor\n",
      "45         Setosa\n",
      "144     Virginica\n",
      "110     Virginica\n",
      "38         Setosa\n",
      "2          Setosa\n",
      "135     Virginica\n",
      "72     Versicolor\n",
      "138     Virginica\n",
      "34         Setosa\n",
      "19         Setosa\n",
      "77     Versicolor\n",
      "101     Virginica\n",
      "63     Versicolor\n",
      "117     Virginica\n",
      "Name: target, dtype: object\n",
      "Test Accuracy: 0.933\n",
      "Training Accuracy: 0.983\n",
      "Loss:  0.2988789340197434\n",
      "Number of Coefs:  2\n",
      "Number of Intercepts:  2\n",
      "Number of Iteration for Which Estimator Ran:  200\n",
      "Name of Output Layer Activation Function:  softmax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#классификация \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)\n",
    "df\n",
    "df = df.rename(columns={'variety': 'target'})\n",
    "X_df, Y_df = df.drop(['target'], axis=1), df.target\n",
    "print('Dataset Size: ', X_df.shape, Y_df.shape)\n",
    "# Функция train_test_split модуля model_selection sklearn поможет нам\n",
    "# разделить данные на два набора: 80% для обучения и 20% для тестирования.\n",
    "# Мы также используем seed(random_state=123) с train_test_split, чтобы мы\n",
    "# всегда получали одно и то же разделение и могли сравнивать и\n",
    "# воспроизволить результаты в будущем.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y_df, train_size=0.80, test_size=0.20, stratify=Y_df, random_state=123)\n",
    "print(X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Для начала натренируем модель MLPClassifier с параметрами по умолчанию\n",
    "# для тренировочных данных.\n",
    "mlp_classifier = MLPClassifier(random_state=123)\n",
    "mlp_classifier.fit(X_train, Y_train)\n",
    "Y_preds = mlp_classifier.predict(X_test)\n",
    "\n",
    "print(Y_preds[:15])\n",
    "print(Y_test[:15])\n",
    "# Метод score для оценки точности моделей классификации\n",
    "print('Test Accuracy: %.3f' % mlp_classifier.score(X_test, Y_test))\n",
    "print('Training Accuracy: %.3f' % mlp_classifier.score(X_train, Y_train))\n",
    "\n",
    "# loss_ — возвращает убыток после завершения процесса обучения\n",
    "print('Loss: ', mlp_classifier.loss_)\n",
    "# coefs_ — возвращает массив длины n_layers-1, где каждый элемент представляет веса, связанные с уровнем i\n",
    "print('Number of Coefs: ', len(mlp_classifier.coefs_))\n",
    "# intercepts_ — возвращает массив длины n_layers-1, где каждый элемент представляет собой перехват, связанный с персептронами слоя i\n",
    "print('Number of Intercepts: ', len(mlp_classifier.intercepts_))\n",
    "# n_iter_ — количество итераций, для которых выполнялась оценка\n",
    "print('Number of Iteration for Which Estimator Ran: ', mlp_classifier.n_iter_)\n",
    "# out_activation_ — возвращает имя функции активации выходного слоя.\n",
    "print('Name of Output Layer Activation Function: ', mlp_classifier.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b18f7e24-22a8-431c-8070-3cf0e78a8f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size:  (30, 1) (30,)\n",
      "Train/Test size:  (24, 1) (6, 1) (24,) (6,)\n",
      "[20.26234628 55.2781752  18.82135812 50.48274487 20.26234628 50.9622879 ]\n",
      "7      54445.0\n",
      "29    121872.0\n",
      "5      56642.0\n",
      "26    116969.0\n",
      "8      64445.0\n",
      "27    112635.0\n",
      "Name: target, dtype: float64\n",
      "Test R^2 Score: -8.796\n",
      "Training R^2 Score: -8.261\n",
      "Loss:  2988058032.1601596\n",
      "Number of Coefs:  2\n",
      "Number of Intercepts:  2\n",
      "Number of Iteration for Which Estimator Ran:  200\n",
      "Name of Output Layer Activation Function:  identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varta\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#регрессия\n",
    "url = 'https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.head(5)\n",
    "df\n",
    "df = df.rename(columns={'Salary':'target'})\n",
    "X_df, Y_df = df.drop(['target'], axis=1), df.target\n",
    "print ('Dataset Size: ', X_df.shape, Y_df.shape)\n",
    "# Функция train_test_split модуля model_selection sklearn поможет нам\n",
    "# разделить данные на два набора: 80% для обучения и 20% для тестирования.\n",
    "# Мы также используем seed(random_state=123) с train_test_split, чтобы мы\n",
    "# всегда получали одно и то же разделение и могли сравнивать и\n",
    "# воспроизволить результаты в будущем.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y_df, train_size = 0.80, test_size = 0.20, random_state = 123)\n",
    "print ('Train/Test size: ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor = MLPRegressor(random_state=123)\n",
    "mlp_regressor.fit(X_train, Y_train)\n",
    "Y_preds = mlp_regressor.predict(X_test)\n",
    "\n",
    "print (Y_preds[:10])\n",
    "print (Y_test[:10])\n",
    "print ('Test R^2 Score: %.3f'%mlp_regressor.score(X_test, Y_test))\n",
    "print ('Training R^2 Score: %.3f'%mlp_regressor.score(X_train, Y_train))\n",
    "\n",
    "print ('Loss: ', mlp_regressor.loss_)\n",
    "print ('Number of Coefs: ', len(mlp_regressor.coefs_))\n",
    "print ('Number of Intercepts: ', len(mlp_regressor.intercepts_))\n",
    "print ('Number of Iteration for Which Estimator Ran: ', mlp_regressor.n_iter_)\n",
    "print ('Name of Output Layer Activation Function: ', mlp_regressor.out_activation_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7bb9e6-08b7-4c85-b2d0-da7e3c4dfb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
